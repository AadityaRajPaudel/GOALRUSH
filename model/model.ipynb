{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccd5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from collections import Counter\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58ee7cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>upset update Facebook texting might cry result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Kenichan I dived many time ball Managed save 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>nationwideclass behaving mad I see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Kwesidei whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            message\n",
       "0  Negative  upset update Facebook texting might cry result...\n",
       "1  Negative  Kenichan I dived many time ball Managed save 5...\n",
       "2  Negative                    whole body feel itchy like fire\n",
       "3  Negative                 nationwideclass behaving mad I see\n",
       "4  Negative                                Kwesidei whole crew"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_text_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e25dadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137d566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_used_data, rest_data = train_test_split(df, train_size = 0.4, stratify=df[\"sentiment\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fffc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639999, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_used_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68025bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = smaller_used_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703d4566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639999, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21283f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7fcd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511999, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef338cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "train_data['message'] = train_data['message'].astype(str)\n",
    "train_data['sentiment'] = train_data['sentiment'].astype(str)\n",
    "test_data['message'] = test_data['message'].astype(str)\n",
    "test_data['sentiment'] = test_data['sentiment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0656d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "oov_token = \"unknown\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(train_data['message'])\n",
    "\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('tokenizer.json', 'w') as json_file:\n",
    "    json_file.write(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9029b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[364, 410, 305, 776, 133, 349, 746, 47, 176, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(str(tokenizer.texts_to_sequences(['There seems to be something wrong with the game today'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba4f3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid= train_test_split(train_data['message'].tolist(),\n",
    "                                                      train_data['sentiment'].tolist(),\n",
    "                                                      test_size=0.1,\n",
    "                                                      stratify = train_data['sentiment'].tolist(),\n",
    "                                                      random_state=8)\n",
    "\n",
    "#further divided traindata into train data and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f10cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:460799\n",
      "Class distributionCounter({'Positive': 230574, 'Negative': 230225})\n",
      "Valid data len:51200\n",
      "Class distributionCounter({'Positive': 25619, 'Negative': 25581})\n"
     ]
    }
   ],
   "source": [
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Class distribution'+str(Counter(y_train)))\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "print('Class distribution'+ str(Counter(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92572ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460799, 50)\n",
      "(51200, 50)\n",
      "(128000, 50)\n"
     ]
    }
   ],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "valid_sequences = tokenizer.texts_to_sequences(X_valid)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['message'].tolist())\n",
    "\n",
    "X_train = pad_sequences(train_sequences, padding='post', maxlen=50)\n",
    "x_valid = pad_sequences(valid_sequences, padding='post', maxlen=50)\n",
    "x_test = pad_sequences(test_sequences, padding='post', maxlen=50)\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "x_valid = np.array(x_valid)\n",
    "x_test = np.array(x_test)\n",
    "print(X_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a87f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "train_labels = le.fit_transform(y_train)\n",
    "train_labels = np.asarray( tf.keras.utils.to_categorical(train_labels))\n",
    "\n",
    "valid_labels = le.transform(y_valid)\n",
    "valid_labels = np.asarray( tf.keras.utils.to_categorical(valid_labels))\n",
    "\n",
    "test_labels = le.transform(test_data['sentiment'].tolist())\n",
    "test_labels = np.asarray(tf.keras.utils.to_categorical(test_labels))\n",
    "\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train,train_labels))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid,valid_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1679732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5676,  439,    2,  180, 3448,  452, 2514, 1166,  280, 3751,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae1801c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 64)            1280064   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 48, 128)           24704     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,305,026\n",
      "Trainable params: 1,305,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "number_of_classes = 2  \n",
    "\n",
    "max_features = 20000\n",
    "embedding_dim = 64\n",
    "sequence_length = 50\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(max_features + 1, embedding_dim, input_length=sequence_length,\n",
    "                                    embeddings_regularizer=regularizers.l2(0.0005)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(128, 3, activation='relu',\n",
    "                                 kernel_regularizer=regularizers.l2(0.0005),\n",
    "                                 bias_regularizer=regularizers.l2(0.0005)))\n",
    "\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(number_of_classes, activation='sigmoid',\n",
    "                                kernel_regularizer=regularizers.l2(0.001),\n",
    "                                bias_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), \n",
    "              optimizer='Nadam', \n",
    "              metrics=[\"CategoricalAccuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5389e72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3600/3600 [==============================] - 109s 30ms/step - loss: 0.5696 - categorical_accuracy: 0.7511 - val_loss: 0.5463 - val_categorical_accuracy: 0.7663\n",
      "Epoch 2/20\n",
      "3600/3600 [==============================] - 104s 29ms/step - loss: 0.5496 - categorical_accuracy: 0.7623 - val_loss: 0.5399 - val_categorical_accuracy: 0.7692\n",
      "Epoch 3/20\n",
      "3600/3600 [==============================] - 109s 30ms/step - loss: 0.5442 - categorical_accuracy: 0.7658 - val_loss: 0.5352 - val_categorical_accuracy: 0.7735\n",
      "Epoch 4/20\n",
      "3600/3600 [==============================] - 101s 28ms/step - loss: 0.5413 - categorical_accuracy: 0.7677 - val_loss: 0.5338 - val_categorical_accuracy: 0.7738\n",
      "Epoch 5/20\n",
      "3600/3600 [==============================] - 101s 28ms/step - loss: 0.5379 - categorical_accuracy: 0.7702 - val_loss: 0.5291 - val_categorical_accuracy: 0.7769\n",
      "Epoch 6/20\n",
      "3600/3600 [==============================] - 104s 29ms/step - loss: 0.5359 - categorical_accuracy: 0.7710 - val_loss: 0.5280 - val_categorical_accuracy: 0.7771\n",
      "Epoch 7/20\n",
      "3600/3600 [==============================] - 106s 29ms/step - loss: 0.5353 - categorical_accuracy: 0.7716 - val_loss: 0.5284 - val_categorical_accuracy: 0.7753\n",
      "Epoch 8/20\n",
      "3600/3600 [==============================] - 107s 30ms/step - loss: 0.5345 - categorical_accuracy: 0.7719 - val_loss: 0.5267 - val_categorical_accuracy: 0.7774\n",
      "Epoch 9/20\n",
      "3600/3600 [==============================] - 101s 28ms/step - loss: 0.5338 - categorical_accuracy: 0.7720 - val_loss: 0.5274 - val_categorical_accuracy: 0.7768\n",
      "Epoch 10/20\n",
      "3600/3600 [==============================] - 103s 29ms/step - loss: 0.5335 - categorical_accuracy: 0.7720 - val_loss: 0.5278 - val_categorical_accuracy: 0.7771\n",
      "Epoch 11/20\n",
      "3600/3600 [==============================] - 103s 28ms/step - loss: 0.5338 - categorical_accuracy: 0.7719 - val_loss: 0.5263 - val_categorical_accuracy: 0.7770\n",
      "Epoch 12/20\n",
      "3600/3600 [==============================] - 101s 28ms/step - loss: 0.5330 - categorical_accuracy: 0.7719 - val_loss: 0.5258 - val_categorical_accuracy: 0.7782\n",
      "Epoch 13/20\n",
      "3600/3600 [==============================] - 102s 28ms/step - loss: 0.5333 - categorical_accuracy: 0.7723 - val_loss: 0.5270 - val_categorical_accuracy: 0.7772\n",
      "Epoch 14/20\n",
      "3600/3600 [==============================] - 99s 27ms/step - loss: 0.5337 - categorical_accuracy: 0.7720 - val_loss: 0.5271 - val_categorical_accuracy: 0.7778\n",
      "Epoch 15/20\n",
      "3600/3600 [==============================] - 99s 28ms/step - loss: 0.5334 - categorical_accuracy: 0.7725 - val_loss: 0.5280 - val_categorical_accuracy: 0.7767\n",
      "Epoch 16/20\n",
      "3600/3600 [==============================] - 99s 28ms/step - loss: 0.5332 - categorical_accuracy: 0.7722 - val_loss: 0.5265 - val_categorical_accuracy: 0.7776\n",
      "Epoch 17/20\n",
      "3600/3600 [==============================] - 100s 28ms/step - loss: 0.5332 - categorical_accuracy: 0.7720 - val_loss: 0.5254 - val_categorical_accuracy: 0.7779\n",
      "Epoch 18/20\n",
      "3600/3600 [==============================] - 99s 27ms/step - loss: 0.5331 - categorical_accuracy: 0.7723 - val_loss: 0.5276 - val_categorical_accuracy: 0.7759\n",
      "Epoch 19/20\n",
      "3600/3600 [==============================] - 101s 28ms/step - loss: 0.5332 - categorical_accuracy: 0.7720 - val_loss: 0.5273 - val_categorical_accuracy: 0.7767\n",
      "Epoch 20/20\n",
      "3600/3600 [==============================] - 99s 28ms/step - loss: 0.5326 - categorical_accuracy: 0.7726 - val_loss: 0.5269 - val_categorical_accuracy: 0.7773\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(train_ds.shuffle(2000).batch(128),\n",
    "                    epochs= epochs ,\n",
    "                    validation_data=valid_ds.batch(128),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3729100",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentimentmodel.keras')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c1caf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentimentmodel.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26601bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "max_features=20000\n",
    "tokenizer = Tokenizer(num_words=max_features)  \n",
    "json_string = tokenizer.to_json()\n",
    "with open('tokenizer.json', 'w') as outfile:\n",
    "    outfile.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae7f8156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x23e0dd30988>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fcc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
